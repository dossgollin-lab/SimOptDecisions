---
title: "Deep Uncertainty and DMDU"
subtitle: "Key concepts and vocabulary"
---

## What is Deep Uncertainty?

In many decision problems, we can characterize the relevant uncertainties with well-estimated probability distributions.
A civil engineer designing a bridge can draw on decades of load-test data; a financial analyst pricing options can calibrate volatility models from market data.

But some decisions involve **deep uncertainty**: situations where decision-makers cannot agree on the appropriate models, probability distributions, or even the set of relevant outcomes.
Climate adaptation, long-lived infrastructure investment, and natural hazard management often fall into this category.
When experts disagree about the *form* of a distribution---not just its parameters---standard expected-value optimization can be misleading [@doss-gollin_subjective:2023].

SimOptDecisions is designed for this setting.
Rather than requiring a single probabilistic model, it supports workflows that explore many plausible futures and stress-test candidate decisions against them.

## DMDU Approaches

Decision Making under Deep Uncertainty (DMDU) is not a single method but a family of approaches that share a common structure:

1. **Generate** candidate decisions (policies)
2. **Stress-test** them across a wide range of plausible futures (scenarios)
3. **Analyze** where each candidate succeeds or fails
4. **Iterate** based on what you learn

Several specific frameworks fit this pattern:

**Robust Decision Making (RDM)** generates candidate strategies, evaluates them across an ensemble of futures, and uses scenario discovery to identify the conditions under which each strategy is vulnerable [@lempert_robust:2000].

**Many-Objective Robust Decision Making (MORDM)** extends RDM by using multi-objective evolutionary optimization to search the policy space, producing Pareto-optimal trade-offs that are then stress-tested for robustness [@kasprzyk_mordm:2013].

**Climate adaptation as a control problem** frames sequential decisions---when to invest, how much to invest---as an optimal control problem under uncertainty, connecting DMDU to the stochastic optimization and reinforcement learning literatures [@herman_control:2020].

SimOptDecisions supports RDM and MORDM workflows natively through `explore()` and `optimize()`.
The framework's separation of scenarios, policies, and simulation logic makes it straightforward to implement the stress-test-and-discover workflow.

## Key Vocabulary

**Scenario**
: A plausible future state of the world.
Not a prediction or a forecast---a scenario represents one internally consistent set of assumptions about uncertain quantities.
In SimOptDecisions, scenarios are concrete data objects containing pre-generated inputs.

**Policy**
: A decision rule mapping system state to actions.
A policy can be as simple as a fixed parameter (elevate 4 feet) or as complex as an adaptive rule (elevate further if cumulative damages exceed a threshold).

**Exploratory modeling**
: Running a model across many scenarios to understand system behavior, rather than to predict a single outcome [@bankes_exploratory:1993].
The goal is to discover *where* a policy is vulnerable, not to find the "right" answer.

**Scenario discovery**
: Identifying the conditions (regions of the scenario space) under which a policy fails to meet performance thresholds.

**Robustness**
: A property of a policy that performs acceptably well across a wide range of plausible futures, even if it is not optimal in any single one [@herman_robustness:2015].

**Pareto front**
: The set of solutions where no objective can be improved without worsening another.
In multi-objective optimization, the Pareto front characterizes the fundamental trade-offs in the problem.

## How SimOptDecisions Fits

The framework maps directly to the DMDU workflow:

| DMDU Step | SimOptDecisions Feature |
|-----------|------------------------|
| Define uncertain futures | `Scenario` type with parameter wrappers |
| Define candidate decisions | `Policy` type with tunable parameters |
| Simulate system response | `simulate()` with user-defined callbacks |
| Explore across futures | `explore()` → YAXArray result matrix |
| Search for optimal trade-offs | `optimize()` → Pareto front |

The framework also draws on ideas from stochastic optimization, optimal control, and engineering design---particularly the separation of uncertain inputs (scenarios) from decision variables (policies) and the use of simulation-based evaluation rather than closed-form objectives.

## Further Reading

For a review of climate risk management and decision-making under uncertainty, see @keller_management:2021.
For an overview of how these methods connect to broader multisector dynamics challenges, see @reed_multisectordynamics:2022.
