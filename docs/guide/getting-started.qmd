---
title: "Quick Reference"
---

This guide shows you exactly what to implement to use SimOptDecisions.

## Workflow Overview

SimOptDecisions supports two main workflows:

1. **Exploratory modeling** with `explore()`: Run all (policy, scenario) combinations and analyze the result matrix to understand where policies succeed or fail
2. **Policy search** with `optimize()`: Use multi-objective optimization to find Pareto-optimal policies, then stress-test them with `explore()`

Both build on `simulate()`, which runs a single (policy, scenario) pair through user-defined callbacks.
See [Framework Architecture](../architecture.qmd) for why the framework is structured this way.

## Checklist: What You Implement

### Types (5 required)

| Type | Purpose | Subtype of | Typical definition |
|------|---------|------------|-------------------|
| Config | Fixed parameters (shared across scenarios) | `AbstractConfig` | Plain struct |
| Scenario | Uncertain parameters (one possible future) | `AbstractScenario` | `@scenariodef` |
| State | Your model's internal state | `AbstractState` | Plain struct |
| Action | What gets decided at each timestep | `AbstractAction` (optional) | Plain struct |
| Policy | Decision rule with tunable parameters | `AbstractPolicy` | `@policydef` |

Use `@scenariodef` and `@policydef` for types whose fields are explored as dimensions by `explore()`.
Config, State, and Action typically have plain fields and are defined as regular Julia structs.
Macros `@configdef` and `@statedef` are available if you need parameter wrappers on those types too.

### Callbacks (5 required)

| Callback | Signature | Returns |
|----------|-----------|---------|
| `initialize` | `(config, scenario, rng)` | `State` |
| `get_action` | `(policy, state, t, scenario)` | `Action` (any type) |
| `run_timestep` | `(state, action, t, config, scenario, rng)` | `(new_state, step_record)` |
| `time_axis` | `(config, scenario)` | Iterable with `length()` |
| `compute_outcome` | `(step_records, config, scenario)` | `Outcome` |

### For `explore()` (parameter wrappers required)

Scenario, Policy, and Outcome fields must use parameter types:

| Type | Use Case |
|------|----------|
| `ContinuousParameter{T}` | Real values |
| `DiscreteParameter{T}` | Integer values |
| `CategoricalParameter{T}` | Categorical values |
| `TimeSeriesParameter{T}` | Time-indexed data |
| `GenericParameter{T}` | Complex objects (skipped in flattening) |

### For Optimization (2 additional methods)

| Method | Signature | Returns |
|--------|-----------|---------|
| `params` | `(policy)` | `Vector` of parameter values |
| `param_bounds` | `(PolicyType)` | Vector of `(min, max)` tuples |

Plus a constructor: `MyPolicy(params::AbstractVector)`.

## Minimal Working Example

Here's a complete example you can copy and modify:

```julia
using SimOptDecisions
using Random

# =============================================================================
# TYPES (using macros for Scenario/Policy)
# =============================================================================

struct MyConfig <: AbstractConfig
    horizon::Int
end

@scenariodef MyScenario begin
    @continuous growth_rate
end

struct MyState{T<:AbstractFloat} <: AbstractState
    value::T
end

struct MyAction <: AbstractAction end

@policydef MyPolicy begin
    @continuous threshold 0.0 10.0
end

# =============================================================================
# CALLBACKS
# =============================================================================

function SimOptDecisions.initialize(config::MyConfig, scenario::MyScenario, rng::AbstractRNG)
    return MyState(1.0)
end

function SimOptDecisions.get_action(policy::MyPolicy, state::MyState, t::TimeStep, scenario::MyScenario)
    return MyAction()
end

function SimOptDecisions.run_timestep(
    state::MyState,
    action::MyAction,
    t::TimeStep,
    config::MyConfig,
    scenario::MyScenario,
    rng::AbstractRNG,
)
    new_value = state.value * (1 + value(scenario.growth_rate))
    step_record = (value=state.value,)
    return (MyState(new_value), step_record)
end

function SimOptDecisions.time_axis(config::MyConfig, scenario::MyScenario)
    return 1:(config.horizon)
end

function SimOptDecisions.compute_outcome(
    step_records::Vector,
    config::MyConfig,
    scenario::MyScenario,
)
    return (final_value=step_records[end].value,)
end

# =============================================================================
# RUN
# =============================================================================

config = MyConfig(10)
scenario = MyScenario(growth_rate = ContinuousParameter(0.05))
policy = MyPolicy(threshold = ContinuousParameter(5.0, (0.0, 10.0)))

result = simulate(config, scenario, policy)
println("Final value: ", result.final_value)
```

## Understanding Each Piece

### Types

**Config** holds parameters that are fixed across all scenarios:

```julia
struct MyConfig <: AbstractConfig
    horizon::Int        # how many timesteps to simulate
end
```

**Scenario** holds uncertain parameters. Use `@scenariodef` with `@continuous`, `@discrete`, etc.:

```julia
@scenariodef MyScenario begin
    @continuous growth_rate  # uncertain: could be 3%, 5%, 7%...
end
```

**State** tracks your model's internal state that evolves over time:

```julia
struct MyState{T<:AbstractFloat} <: AbstractState
    value::T            # current value being tracked
end
```

**Action** represents what gets decided at each timestep. Can be any type:

```julia
struct MyAction <: AbstractAction end
```

**Policy** defines how decisions are made. Use `@policydef` with bounds for optimization:

```julia
@policydef MyPolicy begin
    @continuous threshold 0.0 10.0  # tunable parameter with bounds
end
```

### Callbacks

**initialize**: Create the starting state.

```julia
SimOptDecisions.initialize(config::MyConfig, scenario::MyScenario, rng::AbstractRNG) = MyState(1.0)
```

**get_action**: Given the current state, decide what to do.

```julia
SimOptDecisions.get_action(policy::MyPolicy, state::MyState, t::TimeStep, scenario::MyScenario) = MyAction()
```

**run_timestep**: Apply the action and advance the model. Returns `(new_state, step_record)`.

```julia
function SimOptDecisions.run_timestep(state::MyState, action::MyAction, t::TimeStep, config::MyConfig, scenario::MyScenario, rng::AbstractRNG)
    new_value = state.value * (1 + value(scenario.growth_rate))
    return (MyState(new_value), (value=state.value,))
end
```

**time_axis**: Define when timesteps occur.

```julia
SimOptDecisions.time_axis(config::MyConfig, scenario::MyScenario) = 1:config.horizon
```

**compute_outcome**: Summarize the simulation into an outcome.

```julia
function SimOptDecisions.compute_outcome(step_records::Vector, config::MyConfig, scenario::MyScenario)
    return (final_value=step_records[end].value,)
end
```

## Adding Optimization

With `@policydef`, bounds are already defined. Just add a vector constructor:

```julia
# Use named form to enable adding methods
@policydef OptimizablePolicy begin
    @continuous threshold 0.0 10.0
end

# Add constructor from parameter vector (required for optimization)
OptimizablePolicy(params::AbstractVector) = OptimizablePolicy(
    threshold = ContinuousParameter(params[1], (0.0, 10.0))
)
```

Then set up and run optimization:

```julia
using Metaheuristics
using Statistics

# Aggregate outcomes across scenarios into metrics
function calculate_metrics(outcomes)
    values = [o.final_value for o in outcomes]
    return (expected_value=mean(values), worst_case=minimum(values))
end

# Sample many possible futures
scenarios = [MyScenario(growth_rate = ContinuousParameter(rand() * 0.1)) for _ in 1:100]

# Run optimization (flat API)
result = optimize(
    config, scenarios, OptimizablePolicy, calculate_metrics,
    [maximize(:expected_value)];
    backend=MetaheuristicsBackend()
)

# Get the best policy
best_params = result.pareto_params[1]
best_policy = OptimizablePolicy(best_params)
```

## Next Steps

→ [Tutorial](../tutorial/01-the-problem.qmd) — Learn SimOptDecisions through a complete worked example (house elevation under flood risk)
